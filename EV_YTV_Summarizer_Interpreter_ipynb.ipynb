{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrusere/EV_Market-Analysis-and-Consumer-Behavior/blob/main/EV_YTV_Summarizer_Interpreter_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vay9sVk3XKP6"
      },
      "source": [
        "#### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEaFLj9LEYEa"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller\n",
        "pip install bitsandbytes\n",
        "pip install accelerate\n",
        "pip install trl peft\n",
        "pip install datasets\n",
        "pip install rouge-score\n",
        "pip install huggingface_hub\n",
        "pip install transformers\n",
        "pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-OtqfkbWPRl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NETJlEFuxUiN"
      },
      "source": [
        "# **Fine-tuning the LED Model for Long-Sequence Summarization**\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "In this guide, we'll fine-tune the LED (Longformer Encoder-Decoder) model to perform interpretation and summarization on long sequences of text. The LED model is designed to handle long documents (up to 16,384 tokens), making it suitable for our task involving lengthy inputs.\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "- Install and import necessary libraries.\n",
        "- Prepare and preprocess the dataset.\n",
        "- Fine-tune the LED model for summarization.\n",
        "- Evaluate the fine-tuned model.\n",
        "- Generate summaries using the fine-tuned model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVfcL99TxTmL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUKXK2V2WPst"
      },
      "source": [
        "## **Importing Libraries and loading functions for data Collection and Preparation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQTAiG_7D_G_",
        "outputId": "284e9854-b6a8-4acd-8d97-10a65dde37c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import random\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import warnings\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    TaskType,\n",
        "    get_peft_model,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    LEDTokenizer,\n",
        "    LEDForConditionalGeneration,\n",
        "    BartForConditionalGeneration,\n",
        "    BartTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    EarlyStoppingCallback,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    logging,\n",
        "    pipeline,\n",
        "    AdamW,\n",
        ")\n",
        "\n",
        "\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "from boto3.dynamodb.conditions import Key\n",
        "from boto3.dynamodb.types import TypeDeserializer\n",
        "\n",
        "\n",
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Change the working directory to the desired location in Google Drive\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "\n",
        "# Retrieve the Hugging Face API token from user data\n",
        "huggingface_token = userdata.get('Hugging_Face_Hub_API_TOKEN')\n",
        "# Log in to Hugging Face Hub\n",
        "login(huggingface_token, add_to_git_credential=True)\n",
        "\n",
        "# Setting up AWS Credentials into Environment Variables\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('aws_access_key_id')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('aws_secret_access_key')\n",
        "os.environ['AWS_DEFAULT_REGION'] = userdata.get('aws_region')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6ZaKjgnEg-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HeEhwEMD_se"
      },
      "outputs": [],
      "source": [
        "# Third-party imports\n",
        "import chromedriver_autoinstaller\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import (\n",
        "    ElementNotInteractableException,\n",
        "    TimeoutException,\n",
        ")\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "\n",
        "################################################################################\n",
        "# Initialize and Close WebDriver\n",
        "def init_webdriver():\n",
        "    \"\"\"Initializes and returns a Chrome WebDriver instance with options.\"\"\"\n",
        "    try:\n",
        "        chrome_options = webdriver.ChromeOptions()\n",
        "        chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        chromedriver_autoinstaller.install()  # Automatically install chromedriver\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "        print(\"WebDriver initialized successfully\")\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize WebDriver: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def close_webdriver(driver):\n",
        "    \"\"\"Closes the provided WebDriver instance.\"\"\"\n",
        "    driver.quit()\n",
        "    print(\"WebDriver successfully closed\")\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# YouTube URL and Video ID Handling\n",
        "def get_youtube_url(video_id):\n",
        "    \"\"\"Constructs a YouTube URL from a given video ID.\"\"\"\n",
        "    return f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "\n",
        "def get_youtube_videoID(youtube_url):\n",
        "    \"\"\"Extracts the YouTube video ID from a given YouTube URL.\"\"\"\n",
        "    if not youtube_url:\n",
        "        return None\n",
        "    try:\n",
        "        if \"watch?v=\" in youtube_url:\n",
        "            video_id = youtube_url.split(\"watch?v=\")[1].split(\"&\")[0]\n",
        "            return video_id\n",
        "        elif \"youtu.be/\" in youtube_url:\n",
        "            video_id = youtube_url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
        "            return video_id\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting video ID: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Fetch Comments HTML\n",
        "def get_comments_html(video_url, driver):\n",
        "    \"\"\"\n",
        "    Fetches the HTML content of the comments section from a YouTube video.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video from which to fetch comments.\n",
        "        driver: An initialized WebDriver instance (from Selenium).\n",
        "\n",
        "    Returns:\n",
        "        str: The HTML content of the comments section.\n",
        "\n",
        "    Raises:\n",
        "        TimeoutException: If the comments section does not load within the specified time.\n",
        "    \"\"\"\n",
        "    # Wait until the comments section is loaded\n",
        "    WebDriverWait(driver, 10).until(\n",
        "        EC.presence_of_element_located((By.CSS_SELECTOR, \"ytd-comments\"))\n",
        "    )\n",
        "\n",
        "    # Scroll to the comments section to load initial comments\n",
        "    driver.execute_script(\n",
        "        \"window.scrollTo(0, document.documentElement.scrollHeight);\"\n",
        "    )\n",
        "\n",
        "    # Set initial values for dynamic loading\n",
        "    last_height = driver.execute_script(\n",
        "        \"return document.documentElement.scrollHeight\"\n",
        "    )\n",
        "    scroll_pause_time = 2  # Time to wait between scrolls\n",
        "    max_scrolls = 100  # Max number of scrolls to ensure all comments are loaded\n",
        "    scroll_count = 0\n",
        "\n",
        "    while scroll_count < max_scrolls:\n",
        "        # Scroll down to the bottom\n",
        "        driver.execute_script(\n",
        "            \"window.scrollTo(0, document.documentElement.scrollHeight);\"\n",
        "        )\n",
        "\n",
        "        # Wait for new comments to load dynamically\n",
        "        time.sleep(scroll_pause_time)\n",
        "\n",
        "        # Check the new scroll height and compare it with the last height\n",
        "        new_height = driver.execute_script(\n",
        "            \"return document.documentElement.scrollHeight\"\n",
        "        )\n",
        "        if new_height == last_height:\n",
        "            # If the height hasn't changed, try one more scroll to ensure all comments are loaded\n",
        "            time.sleep(scroll_pause_time)\n",
        "            new_height = driver.execute_script(\n",
        "                \"return document.documentElement.scrollHeight\"\n",
        "            )\n",
        "            if new_height == last_height:\n",
        "                print(\"All comments have been loaded.\")\n",
        "                break\n",
        "\n",
        "        last_height = new_height\n",
        "        scroll_count += 1\n",
        "\n",
        "    # Get the HTML of the comments section\n",
        "    comments_html = driver.page_source\n",
        "\n",
        "    # Close the driver\n",
        "    close_webdriver(driver)\n",
        "\n",
        "    return comments_html\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Parse Comments\n",
        "def get_comment_thread_renderers(comments_html):\n",
        "    \"\"\"\n",
        "    Parses the provided HTML content to extract YouTube comment threads.\n",
        "\n",
        "    Args:\n",
        "        comments_html (str): The HTML content of the comments section of a YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of `ytd-comment-thread-renderer` elements found in the HTML.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(comments_html, \"html.parser\")\n",
        "    comment_thread_renderers = soup.find_all(\n",
        "        \"ytd-comment-thread-renderer\",\n",
        "        class_=\"style-scope ytd-item-section-renderer\",\n",
        "    )\n",
        "    return comment_thread_renderers\n",
        "\n",
        "\n",
        "def get_comments(comment_thread_renderers):\n",
        "    \"\"\"\n",
        "    Extracts comments and associated data from the list of comment thread renderers.\n",
        "\n",
        "    Args:\n",
        "        comment_thread_renderers (list): List of 'ytd-comment-thread-renderer' elements.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing a list of comment texts and a list of dictionaries with comment data.\n",
        "    \"\"\"\n",
        "    comments = []\n",
        "    comments_data = []\n",
        "\n",
        "    for comment_thread_renderer in comment_thread_renderers:\n",
        "        # Extract the comment text\n",
        "        comment_text_element = comment_thread_renderer.find(\n",
        "            \"yt-attributed-string\", id=\"content-text\"\n",
        "        )\n",
        "        comment_text = (\n",
        "            comment_text_element.get_text(strip=True)\n",
        "            if comment_text_element\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        # Extract the number of likes\n",
        "        like_count_element = comment_thread_renderer.find(\n",
        "            \"span\", class_=\"style-scope ytd-comment-engagement-bar\"\n",
        "        )\n",
        "        like_count = (\n",
        "            like_count_element.get_text(strip=True)\n",
        "            if like_count_element\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        # Extract the number of replies\n",
        "        reply_count_element = comment_thread_renderer.find(\n",
        "            \"ytd-button-renderer\", id=\"more-replies\"\n",
        "        )\n",
        "        reply_count = (\n",
        "            reply_count_element.get_text(strip=True)\n",
        "            if reply_count_element\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        comments.append(comment_text)\n",
        "        comments_data.append(\n",
        "            {\n",
        "                \"comment_text\": comment_text,\n",
        "                \"like_count\": like_count,\n",
        "                \"reply_count\": reply_count,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return comments, comments_data\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Retrieve Video Comments\n",
        "def get_video_comments(video_url, driver):\n",
        "    \"\"\"\n",
        "    Retrieves comments from the provided YouTube video URL.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video.\n",
        "        driver: An initialized WebDriver instance (from Selenium).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of comments and their data.\n",
        "    \"\"\"\n",
        "    comments_html = get_comments_html(video_url, driver)\n",
        "    comment_thread_renderers = get_comment_thread_renderers(comments_html)\n",
        "    _, comments_data = get_comments(comment_thread_renderers)\n",
        "    return comments_data\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Clean and Summarize Video Description\n",
        "def clean_description(video_data_dict, model_path=\"./Bart-Desc-Sum-fine-tuned-lora-model\"):\n",
        "    \"\"\"\n",
        "    Cleans and summarizes YouTube video descriptions using a fine-tuned LoRA model.\n",
        "\n",
        "    Args:\n",
        "        video_data_dict (dict): A dictionary containing video data with keys 'channel_name', 'video_title', and 'video_description'.\n",
        "        model_path (str, optional): Path to the fine-tuned summarization model.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and summarized description.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Load the fine-tuned model and tokenizer\n",
        "    pipe = pipeline(\"summarization\", model=model_path, tokenizer=model_path, device=device)\n",
        "\n",
        "    # Construct the input text\n",
        "    input_text = (\n",
        "        f\"Channel: {video_data_dict['channel_name']}, \"\n",
        "        f\"Title: {video_data_dict['video_title']}, \"\n",
        "        f\"Description: {video_data_dict['video_description']}\"\n",
        "    )\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "    input_length = len(tokenizer.encode(input_text))\n",
        "    max_length = int(input_length * 0.5)\n",
        "\n",
        "\n",
        "    # Generate a cleaned description\n",
        "    cleaned_description = pipe(input_text, max_length=max_length)[0][\"summary_text\"]\n",
        "\n",
        "    return cleaned_description\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Fetch Video Data\n",
        "def get_video_data(video_id):\n",
        "    \"\"\"\n",
        "    Fetches video data from YouTube given a video ID.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The ID of the YouTube video to fetch data for.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the video data with keys:\n",
        "            - 'channel_name'\n",
        "            - 'video_title'\n",
        "            - 'video_description'\n",
        "            - 'comments'\n",
        "    \"\"\"\n",
        "    driver = init_webdriver()\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    video_data = {}\n",
        "\n",
        "    try:\n",
        "        driver.get(video_url)\n",
        "\n",
        "        # Handle YouTube consent dialog if it appears\n",
        "        try:\n",
        "            consent_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.XPATH, '//button[contains(., \"I agree\")]')\n",
        "                )\n",
        "            )\n",
        "            consent_button.click()\n",
        "        except TimeoutException:\n",
        "            print(\"No consent dialog found or already handled.\")\n",
        "\n",
        "        # Handle any other potential modal dialogs that might pop up\n",
        "        try:\n",
        "            dialog_close_button = WebDriverWait(driver, 5).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.XPATH, '//button[@aria-label=\"Close\"]')\n",
        "                )\n",
        "            )\n",
        "            dialog_close_button.click()\n",
        "        except TimeoutException:\n",
        "            print(\"No additional modal dialogs found.\")\n",
        "\n",
        "        try:\n",
        "            # Wait for the bottom-row element to be present\n",
        "            WebDriverWait(driver, 20).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, '//*[@id=\"bottom-row\"]')\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Locate and click the expand button if it exists\n",
        "            try:\n",
        "                expand_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.presence_of_element_located(\n",
        "                        (By.XPATH, '//tp-yt-paper-button[@id=\"expand\"]')\n",
        "                    )\n",
        "                )\n",
        "                # Use JavaScript to click the element to bypass any overlay issues\n",
        "                driver.execute_script(\n",
        "                    \"arguments[0].scrollIntoView();\", expand_button\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].click();\", expand_button)\n",
        "            except TimeoutException:\n",
        "                pass  # Ignore if the expand button is not found\n",
        "\n",
        "            # Wait for elements to be visible and extract data\n",
        "            expanded_description = WebDriverWait(driver, 10).until(\n",
        "                EC.visibility_of_element_located(\n",
        "                    (By.ID, \"description-inline-expander\")\n",
        "                )\n",
        "            )\n",
        "            title_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (\n",
        "                        By.XPATH,\n",
        "                        '//h1[@class=\"style-scope ytd-watch-metadata\"]//yt-formatted-string',\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "            channel_name_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (\n",
        "                        By.XPATH,\n",
        "                        '//ytd-channel-name[@id=\"channel-name\"]//yt-formatted-string//a',\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "\n",
        "            video_data = {\n",
        "                \"channel_name\": channel_name_element.text,\n",
        "                \"video_title\": title_element.text,\n",
        "                \"video_description\": expanded_description.text,\n",
        "            }\n",
        "\n",
        "            # Clean the description\n",
        "            cleaned_description = clean_description(video_data)\n",
        "            video_data[\"video_description\"] = cleaned_description\n",
        "\n",
        "            # Fetch comments\n",
        "            comments_data = get_video_comments(video_url, driver)\n",
        "            video_data[\"comments\"] = comments_data\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(\n",
        "                f\"Error processing {video_url}: Elements not found within timeout.\"\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_url}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Close the browser when done\n",
        "        close_webdriver(driver)\n",
        "\n",
        "    return video_data\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Data Conversion and Cleaning\n",
        "def convert_to_int(count_str):\n",
        "    \"\"\"\n",
        "    Converts a string representing a large number with suffixes 'K', 'M', or 'B' into an integer.\n",
        "\n",
        "    Args:\n",
        "        count_str (str or int): The count string to convert.\n",
        "\n",
        "    Returns:\n",
        "        int: The numerical equivalent of the input string.\n",
        "    \"\"\"\n",
        "    if count_str is None:\n",
        "        return 0\n",
        "\n",
        "    if isinstance(count_str, str):\n",
        "        count_str = count_str.strip()\n",
        "        multiplier = 1\n",
        "\n",
        "        if \"K\" in count_str:\n",
        "            multiplier = 1000\n",
        "            count_str = count_str.replace(\"K\", \"\").strip()\n",
        "        elif \"M\" in count_str:\n",
        "            multiplier = 1_000_000\n",
        "            count_str = count_str.replace(\"M\", \"\").strip()\n",
        "        elif \"B\" in count_str:\n",
        "            multiplier = 1_000_000_000\n",
        "            count_str = count_str.replace(\"B\", \"\").strip()\n",
        "\n",
        "        # Extract numerical part\n",
        "        numeric_part = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", count_str)\n",
        "        if numeric_part:\n",
        "            count_str = numeric_part[0]\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            return int(float(count_str) * multiplier)\n",
        "        except ValueError:\n",
        "            return 0\n",
        "    else:\n",
        "        try:\n",
        "            return int(count_str)\n",
        "        except ValueError:\n",
        "            return 0\n",
        "\n",
        "\n",
        "def convert_video_comments_to_dataframe(video_data):\n",
        "    \"\"\"\n",
        "    Converts the video data and its comments into a list of dictionaries.\n",
        "\n",
        "    Args:\n",
        "        video_data (dict): The video data containing comments.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries with comment data.\n",
        "    \"\"\"\n",
        "    if \"comments\" not in video_data or not video_data[\"comments\"]:\n",
        "        print(\"No comments to convert.\")\n",
        "        return []\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for comment in video_data[\"comments\"]:\n",
        "        row = {\n",
        "            \"channel_name\": video_data[\"channel_name\"],\n",
        "            \"video_title\": video_data[\"video_title\"],\n",
        "            \"video_description\": video_data[\"video_description\"],\n",
        "            \"comment_text\": comment[\"comment_text\"],\n",
        "            \"like_count\": convert_to_int(comment[\"like_count\"]),\n",
        "            \"reply_count\": convert_to_int(comment[\"reply_count\"]),\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    print(f\"Converted comments to DataFrame with {len(df)} rows.\")\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Prepare the Test Data for Inference\n",
        "def prepare_test_data_from_dict(data_dict, for_inference=True):\n",
        "    \"\"\"\n",
        "    Prepares the test data for inference from a dictionary.\n",
        "\n",
        "    Args:\n",
        "        data_dict (list): List of dictionaries containing comment data.\n",
        "        for_inference (bool, optional): If True, the output is left empty.\n",
        "\n",
        "    Returns:\n",
        "        Dataset: A Hugging Face Dataset object.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(data_dict)\n",
        "\n",
        "    formatted_input_data = [\n",
        "        {\n",
        "            \"input\": (\n",
        "                f\"Channel Name: {row['channel_name']}\\n\"\n",
        "                f\"Video Title: {row['video_title']}\\n\"\n",
        "                f\"Description: {row['video_description']}\\n\"\n",
        "                f\"Comment Text: {row['comment_text']}\\n\"\n",
        "            ),\n",
        "            \"output\": \"Sentiment: , Explanation: \",\n",
        "        }\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    return Dataset.from_list(formatted_input_data)\n",
        "\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Tokenizes the dataset for model inference using the provided tokenizer.\n",
        "\n",
        "    Args:\n",
        "        dataset (Dataset): The dataset to tokenize.\n",
        "        tokenizer: The tokenizer to use.\n",
        "\n",
        "    Returns:\n",
        "        Dataset: The tokenized dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def tokenize_data(example):\n",
        "        return tokenizer(\n",
        "            example[\"input\"],\n",
        "            max_length=512,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "    return dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "\n",
        "def run_inference(model, tokenizer, tokenized_dataset):\n",
        "    \"\"\"\n",
        "    Runs inference on the tokenized dataset using the provided model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        model: The fine-tuned model.\n",
        "        tokenizer: The tokenizer to use.\n",
        "        tokenized_dataset (Dataset): The tokenized dataset.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predictions.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    for example in tokenized_dataset:\n",
        "        inputs = tokenizer(\n",
        "            example[\"input\"],\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=512,\n",
        "        )\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs, max_length=150, num_beams=5, early_stopping=True\n",
        "            )\n",
        "\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def get_predictions_from_data_dict(data_dict, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Processes the data from a dictionary, runs inference, and returns the predictions.\n",
        "\n",
        "    Args:\n",
        "        data_dict (list): List of dictionaries containing comment data.\n",
        "        model: The fine-tuned model.\n",
        "        tokenizer: The tokenizer to use.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predictions.\n",
        "    \"\"\"\n",
        "    formatted_dataset = prepare_test_data_from_dict(data_dict, for_inference=True)\n",
        "    tokenized_dataset = tokenize_dataset(formatted_dataset, tokenizer)\n",
        "    predictions = run_inference(model, tokenizer, tokenized_dataset)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Sentiment and Explanation Processing\n",
        "def split_sentiment_explanation(item):\n",
        "    \"\"\"\n",
        "    Splits the model's output into sentiment and explanation.\n",
        "\n",
        "    Args:\n",
        "        item (str): The model's output string.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the sentiment and explanation.\n",
        "    \"\"\"\n",
        "    sentiment_part, explanation_part = item.split(\", Explanation: \")\n",
        "    sentiment = sentiment_part.replace(\"Sentiment: \", \"\").strip()\n",
        "    explanation = explanation_part.strip()\n",
        "    print(f\"Sentiment: {sentiment}, Explanation: {explanation}\")\n",
        "    return sentiment, explanation\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Saving Data to S3\n",
        "def save_data_to_s3(video_id, processed_video_data, bucket_name =  'experiment-api-data-bucket'):\n",
        "    \"\"\"\n",
        "    Saves processed_video_data to an S3 bucket.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "        processed_video_data (list): The processed video data to save.\n",
        "        bucket_name (str): The name of the S3 bucket.\n",
        "\n",
        "    Returns:\n",
        "        str: The S3 object key where the data is stored.\n",
        "    \"\"\"\n",
        "    s3 = boto3.client('s3')\n",
        "\n",
        "    # Serialize data to JSON\n",
        "    data_json = json.dumps(processed_video_data)\n",
        "\n",
        "    # Define the S3 object key\n",
        "    s3_key = f\"{video_id}.json\"\n",
        "\n",
        "    # Save to S3\n",
        "    try:\n",
        "        s3.put_object(Bucket=bucket_name, Key=s3_key, Body=data_json)\n",
        "        print(f\"Data for video_id '{video_id}' saved to S3 bucket '{bucket_name}'.\")\n",
        "        return s3_key\n",
        "    except ClientError as e:\n",
        "        print(f\"Error saving data to S3: {e.response['Error']['Message']}\")\n",
        "        return None\n",
        "\n",
        "################################################################################\n",
        "# Saving S3 Reference to DynamoDB\n",
        "def save_s3_reference_to_dynamodb(video_id, s3_key, table_name='YouTubeVideoData'):\n",
        "    \"\"\"\n",
        "    Stores the S3 object key and last-updated-on timestamp in DynamoDB, indexed by video_id and last-updated-on.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "        s3_key (str): The S3 object key where the data is stored.\n",
        "        table_name (str): The name of the DynamoDB table.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    dynamodb = boto3.resource('dynamodb')\n",
        "    table = dynamodb.Table(table_name)\n",
        "\n",
        "    # Get the current UTC datetime in ISO 8601 format\n",
        "    current_time = datetime.datetime.utcnow().isoformat()\n",
        "\n",
        "    try:\n",
        "        table.put_item(\n",
        "            Item={\n",
        "                'video_id': video_id,\n",
        "                'last-updated-on': current_time,\n",
        "                's3_key': s3_key\n",
        "            }\n",
        "        )\n",
        "        print(f\"S3 reference for video_id '{video_id}' saved to DynamoDB with timestamp '{current_time}'.\")\n",
        "    except ClientError as e:\n",
        "        print(f\"Error saving S3 reference to DynamoDB: {e.response['Error']['Message']}\")\n",
        "\n",
        "################################################################################\n",
        "# Retrieving S3 Reference from DynamoDB\n",
        "\n",
        "def get_latest_s3_reference_from_dynamodb(video_id, table_name='YouTubeVideoData'):\n",
        "    \"\"\"\n",
        "    Retrieves the latest S3 object key and last-updated-on timestamp from DynamoDB using the video_id.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "        table_name (str): The name of the DynamoDB table.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing 's3_key' and 'last-updated-on'.\n",
        "    \"\"\"\n",
        "    dynamodb = boto3.resource('dynamodb')\n",
        "    table = dynamodb.Table(table_name)\n",
        "\n",
        "    try:\n",
        "        response = table.query(\n",
        "            KeyConditionExpression=Key('video_id').eq(video_id),\n",
        "            ScanIndexForward=False,  # Sorts results in descending order\n",
        "            Limit=1  # Get only the latest item\n",
        "        )\n",
        "        items = response.get('Items')\n",
        "        if items:\n",
        "            item = items[0]\n",
        "            print(f\"S3 reference for video_id '{video_id}' retrieved from DynamoDB.\")\n",
        "            return {\n",
        "                's3_key': item.get('s3_key'),\n",
        "                'last-updated-on': item.get('last-updated-on')\n",
        "            }\n",
        "        else:\n",
        "            print(f\"No data found for video_id '{video_id}'.\")\n",
        "            return None\n",
        "    except ClientError as e:\n",
        "        print(f\"Error retrieving S3 reference from DynamoDB: {e.response['Error']['Message']}\")\n",
        "        return None\n",
        "\n",
        "################################################################################\n",
        "# Retrieve Data from S3\n",
        "\n",
        "def get_data_from_s3(video_id, bucket_name='experiment-api-data-bucket'):\n",
        "    \"\"\"\n",
        "    Retrieves processed_video_data from S3 using the video_id.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "        bucket_name (str): The name of the S3 bucket.\n",
        "\n",
        "    Returns:\n",
        "        list: The processed_video_data associated with the video_id.\n",
        "    \"\"\"\n",
        "    s3 = boto3.client('s3')\n",
        "    s3_key = f\"{video_id}.json\"\n",
        "\n",
        "    try:\n",
        "        response = s3.get_object(Bucket=bucket_name, Key=s3_key)\n",
        "        data_json = response['Body'].read().decode('utf-8')\n",
        "        data = json.loads(data_json)\n",
        "        print(f\"Data for video_id '{video_id}' retrieved from S3.\")\n",
        "        return data\n",
        "    except ClientError as e:\n",
        "        print(f\"Error retrieving data from S3: {e.response['Error']['Message']}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Main Execution Flow\n",
        "def main(youtube_url):\n",
        "    \"\"\"\n",
        "    Main function to execute all steps.\n",
        "\n",
        "    Args:\n",
        "        youtube_url (str): The YouTube video URL.\n",
        "    \"\"\"\n",
        "    video_id = get_youtube_videoID(youtube_url)\n",
        "    if not video_id:\n",
        "        print(\"Invalid YouTube URL.\")\n",
        "        return\n",
        "\n",
        "    # Step 1 & 2: Collect comments and clean description\n",
        "    video_data = get_video_data(video_id)\n",
        "    if not video_data:\n",
        "        print(\"Failed to retrieve video data.\")\n",
        "        return\n",
        "\n",
        "    # Convert comments to DataFrame\n",
        "    data_dict = convert_video_comments_to_dataframe(video_data)\n",
        "    if not data_dict:\n",
        "        print(\"No comments data available.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Sentiment Analysis\n",
        "    model_path = \"./SA-bart-fine-tuned-lora-model\"  # Update with your model path\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "    model.eval()\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    predictions = get_predictions_from_data_dict(data_dict, model, tokenizer)\n",
        "    print(\"Sentiment analysis completed.\")\n",
        "\n",
        "    processed_video_data = [\n",
        "        {**data_entry, \"sentiment_&_explanations\": prediction}\n",
        "        for data_entry, prediction in zip(data_dict, predictions)\n",
        "    ]\n",
        "\n",
        "    return processed_video_data\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "def retrieve_or_extract_video_data(youtube_url):\n",
        "    \"\"\"\n",
        "    Given a YouTube URL, retrieve the video data from AWS if available;\n",
        "    if not available, extract from YouTube and store it.\n",
        "    \"\"\"\n",
        "    # Get video ID\n",
        "    video_id = get_youtube_videoID(youtube_url)\n",
        "    if not video_id:\n",
        "        print(\"Invalid YouTube URL.\")\n",
        "        return None\n",
        "\n",
        "    # Try to retrieve S3 reference from DynamoDB\n",
        "    s3_reference = get_latest_s3_reference_from_dynamodb(video_id)\n",
        "    if s3_reference:\n",
        "        # Data exists, retrieve from S3\n",
        "        processed_video_data = get_data_from_s3(video_id)\n",
        "        print(\"Data retrieved from AWS.\")\n",
        "        return processed_video_data\n",
        "    else:\n",
        "        # Data does not exist, extract from YouTube\n",
        "        processed_video_data = main(youtube_url)\n",
        "\n",
        "        if not processed_video_data:\n",
        "            print(\"No processed data to save. Exiting.\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        bucket_name = 'experiment-api-data-bucket'\n",
        "        # Save data to S3\n",
        "        s3_key = save_data_to_s3(video_id, processed_video_data)\n",
        "\n",
        "        if s3_key:\n",
        "            # Save S3 reference and timestamp to DynamoDB\n",
        "            save_s3_reference_to_dynamodb(video_id, s3_key)\n",
        "        else:\n",
        "            print(\"Failed to save data to S3. Skipping DynamoDB update.\")\n",
        "\n",
        "    return processed_video_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recreate_dataset_without_comments(dataset):\n",
        "    \"\"\"\n",
        "    Recreates a dataset by removing specific fields (`comment_text`, `like_count`, and `reply_count`)\n",
        "    and aggregating `sentiment_&_explanations` based on `channel_name`, `video_title`, and `video_description`.\n",
        "\n",
        "    Parameters:\n",
        "    dataset (list of dict): The original dataset, where each dictionary contains fields such as\n",
        "                            'channel_name', 'video_title', 'video_description', 'comment_text',\n",
        "                            'like_count', 'reply_count', and 'sentiment_&_explanations'.\n",
        "\n",
        "    Returns:\n",
        "    list of dict: A list of dictionaries with each dictionary representing unique video details.\n",
        "                  Each dictionary contains:\n",
        "                  - 'channel_name': Name of the channel.\n",
        "                  - 'video_title': Title of the video.\n",
        "                  - 'video_description': Description of the video.\n",
        "                  - 'sentiment_&_explanations_list': List of aggregated sentiment explanations for the video.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    video_dict = {}\n",
        "\n",
        "    # Grouping sentiment explanations by unique video details\n",
        "    for item in dataset:\n",
        "        key = (item['channel_name'], item['video_title'], item['video_description'])\n",
        "        if key not in video_dict:\n",
        "            video_dict[key] = []\n",
        "        video_dict[key].append(item['sentiment_&_explanations'])\n",
        "\n",
        "    # Creating the result list with the desired format\n",
        "    for key, sentiment_explanations in video_dict.items():\n",
        "        result.append({\n",
        "            'channel_name': key[0],\n",
        "            'video_title': key[1],\n",
        "            'video_description': key[2],\n",
        "            'sentiment_&_explanations_list': sentiment_explanations\n",
        "        })\n",
        "\n",
        "    return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pWnKAUpkGkYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAyQU5XqJHYC"
      },
      "outputs": [],
      "source": [
        "def sample_sentiments(data, sample_size=100):\n",
        "    \"\"\"\n",
        "    Returns a random sample of 'sentiment_&_explanations' entries from the given data dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        data (dict): A dictionary containing the dataset.\n",
        "        sample_size (int): The maximum number of entries to sample.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing a sample of 'sentiment_&_explanations_list'.\n",
        "    \"\"\"\n",
        "    # Ensure the sample size does not exceed the length of 'sentiment_&_explanations_list'\n",
        "    num_entries = len(data.get('sentiment_&_explanations_list', []))\n",
        "    sample_size = min(sample_size, num_entries)\n",
        "\n",
        "    # Get the random sample\n",
        "    sampled_sentiments = random.sample(data['sentiment_&_explanations_list'], sample_size)\n",
        "\n",
        "    # Return the modified data with the sampled sentiments\n",
        "    return {\n",
        "        'channel_name': data.get('channel_name'),\n",
        "        'video_time': data.get('video_time'),\n",
        "        'video_description': data.get('video_description'),\n",
        "        'sampled_sentiment_&_explanations': sampled_sentiments\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24foq041XxyT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK6fFYcyzAKW"
      },
      "source": [
        "## **Prepare the Dataset**\n",
        "\n",
        "- We need to prepare our dataset for fine-tuning. Since we have specific input data, we'll structure it appropriately.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNQj8EZMbKW4",
        "outputId": "91225b03-3c57-45c7-98fb-ef9aac902644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type: <class 'list'> <---->  Data length 56\n"
          ]
        }
      ],
      "source": [
        "with open('/content/drive/MyDrive/NLP_Data/summary_interp_train_valid_data.json', 'r') as f:\n",
        "  summary_interp_train_valid_data = json.load(f)\n",
        "print(f\"Data type: {type(summary_interp_train_valid_data)} <---->  Data length {len(summary_interp_train_valid_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary_interp_train_valid_data = []\n",
        "# for num in range(len(list_of_Training_videoIDs)):\n",
        "#   processed_data = recreate_dataset_without_comments(data[list_of_Training_videoIDs[num]])\n",
        "#   processed_data = sample_sentiments(processed_data[0])\n",
        "#   processed_data['summary_interp'] = summaryInterp_dict[list_of_Training_videoIDs[num]]\n",
        "#   summary_interp_train_valid_data.append(processed_data)\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/NLP_Data/summary_interp_train_valid_data.json', 'w') as f:\n",
        "#   json.dump(summary_interp_train_valid_data, f)\n"
      ],
      "metadata": {
        "id": "8lm88fUyVRqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-c5NZpDfr38"
      },
      "outputs": [],
      "source": [
        "# # Create the prompt text\n",
        "# prompt = f\"\"\"\n",
        "# You are given information about a YouTube channel's video, along with viewer sentiment and explanations from various comments. Summarize the overall interpretation of the sentiment and explanations provided.\n",
        "\n",
        "# Input:\n",
        "# {processed_data}\n",
        "\n",
        "# Instructions:\n",
        "# 1. Review the input data, focusing on the sentiment and explanations.\n",
        "# 2. Identify the general mood or attitude expressed by the viewers.\n",
        "# 3. Provide an overall interpretation of the viewers' reactions and any specific themes or concerns they raise.\n",
        "\n",
        "# Output: A concise summary of the overall interpretation, highlighting the sentiment, key points, and any underlying motivations or concerns expressed by viewers in their comments.\n",
        "# \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsF6iTLbx8CQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggYtisAbcY3z"
      },
      "outputs": [],
      "source": [
        "# # Define the API request URL\n",
        "# url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet,statistics&id={video_id}&key={userdata.get('YouTubeAPI_key')}\"\n",
        "\n",
        "# # Send a GET request to the API\n",
        "# response = requests.get(url).json()\n",
        "\n",
        "# # Check if the response contains items\n",
        "# if \"items\" in response and response[\"items\"]:\n",
        "#     # Extract required information\n",
        "#     video = response[\"items\"][0]\n",
        "#     title = video[\"snippet\"][\"title\"]\n",
        "#     thumbnail_url = video[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
        "#     view_count = video[\"statistics\"][\"viewCount\"]\n",
        "#     like_count = video[\"statistics\"].get(\"likeCount\", \"Not available\")  # Handle cases with no likeCount\n",
        "#     date_posted = video[\"snippet\"][\"publishedAt\"]\n",
        "\n",
        "\n",
        "#     # Print the extracted information\n",
        "#     print(\"Channel Name:\", processed_data['channel_name'])\n",
        "#     print(\"Title:\", title)\n",
        "#     display(Image(thumbnail_url))\n",
        "#     print(\"Views:\", view_count)\n",
        "#     print(\"Likes:\", like_count)\n",
        "#     print(\"Date Posted:\", date_posted)\n",
        "#     print(\"Description:\", processed_data['video_description'])\n",
        "# else:\n",
        "#     print(\"No video found or invalid video ID.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYcCIvWI3ytU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtLkXxBUT9pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input and target texts based on the data\n",
        "input_texts = [\n",
        "    f\"\"\"\n",
        "    You are given information about a YouTube channel's video (Channel Name, Video Title, and Video Description are provided for context), along with viewer sentiment and explanations from various comments.\n",
        "    Summarize and provide an overall interpretation of the sentiment and explanations provided.\n",
        "\n",
        "    Channel Name: {video_data.get('channel_name', 'N/A')}\n",
        "    Video Title: {video_data.get('video_title', 'N/A')}\n",
        "    Video Description: {video_data.get('video_description', 'N/A')}\n",
        "\n",
        "    Viewer Sentiments and Explanations:\n",
        "    {video_data.get('sampled_sentiment_&_explanations', [])}\n",
        "\n",
        "    Instructions:\n",
        "    1. Review the input data, focusing on the sentiment and explanations.\n",
        "    2. Identify the general mood or attitude expressed by the viewers.\n",
        "    3. Provide an overall interpretation of the viewers' reactions and any specific themes or concerns they raise.\n",
        "    \"\"\"\n",
        "    for video_data in summary_interp_train_valid_data if isinstance(video_data, dict)\n",
        "]\n",
        "\n",
        "target_texts = [\n",
        "    f\"\"\"\n",
        "    Summary and Overall Interpretation: {video_data.get('summary_interp', 'N/A')}\"\"\"\n",
        "    for video_data in summary_interp_train_valid_data if isinstance(video_data, dict)\n",
        "]\n",
        "\n",
        "# Define a custom Dataset class\n",
        "class EVSummaryDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_input_length=16384, max_target_length=512):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ensure idx is an integer\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.item()\n",
        "        elif isinstance(idx, list):\n",
        "            idx = idx[0]\n",
        "\n",
        "        # Tokenize the input text\n",
        "        inputs = self.tokenizer(\n",
        "            self.inputs[idx],\n",
        "            max_length=self.max_input_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        targets = self.tokenizer(\n",
        "            self.targets[idx],\n",
        "            max_length=self.max_target_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "\n",
        "        input_ids = inputs.input_ids\n",
        "        attention_mask = inputs.attention_mask\n",
        "        target_ids = targets.input_ids\n",
        "        target_attention_mask = targets.attention_mask\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": target_ids,\n",
        "            \"decoder_attention_mask\": target_attention_mask\n",
        "        }\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = 'allenai/led-base-16384'\n",
        "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Set pad_token_id if not already set\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "if model.config.pad_token_id is None:\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "dataset = EVSummaryDataset(input_texts, target_texts, tokenizer)\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move all batch data to the same device as the model\n",
        "        input_ids = batch[\"input_ids\"].to(device).squeeze(1)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device).squeeze(1)\n",
        "        labels = batch[\"labels\"].to(device).squeeze(1)\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device).squeeze(1)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=decoder_attention_mask\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}\")\n",
        "\n",
        "# Define paths to save the model and tokenizer\n",
        "model_save_path = \"./summaryInterp_trained_led-base-16384\"\n",
        "tokenizer_save_path = \"./summaryInterp_trained_led-base-16384\"\n",
        "\n",
        "# After training, save the model and tokenizer\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(tokenizer_save_path)\n"
      ],
      "metadata": {
        "id": "x8bwhAVdZhi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b33165f-9cbd-4d23-c649-299802da48c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 6.37311852829797\n",
            "Epoch 2/20, Loss: 3.2244754987103597\n",
            "Epoch 3/20, Loss: 2.224991817559515\n",
            "Epoch 4/20, Loss: 1.4753460862806864\n",
            "Epoch 5/20, Loss: 0.9993697053619793\n",
            "Epoch 6/20, Loss: 0.7415628454514912\n",
            "Epoch 7/20, Loss: 0.5888823276119572\n",
            "Epoch 8/20, Loss: 0.4793521777859756\n",
            "Epoch 9/20, Loss: 0.39642272889614105\n",
            "Epoch 10/20, Loss: 0.32245879833187374\n",
            "Epoch 11/20, Loss: 0.26039091125130653\n",
            "Epoch 12/20, Loss: 0.20629392763865845\n",
            "Epoch 13/20, Loss: 0.15938307344913483\n",
            "Epoch 14/20, Loss: 0.12194029361541782\n",
            "Epoch 15/20, Loss: 0.09680147502305252\n",
            "Epoch 16/20, Loss: 0.19730923457869462\n",
            "Epoch 17/20, Loss: 0.10860623246324914\n",
            "Epoch 18/20, Loss: 0.07436871901154518\n",
            "Epoch 19/20, Loss: 0.05699853226542473\n",
            "Epoch 20/20, Loss: 0.04644504046466734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./summaryInterp_trained_led-base-16384/tokenizer_config.json',\n",
              " './summaryInterp_trained_led-base-16384/special_tokens_map.json',\n",
              " './summaryInterp_trained_led-base-16384/vocab.json',\n",
              " './summaryInterp_trained_led-base-16384/merges.txt',\n",
              " './summaryInterp_trained_led-base-16384/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pushing to HuggingFace\n",
        "\n",
        "model.push_to_hub(\"kkrusere/summaryInterp_trained_led-base-16384\")\n",
        "tokenizer.push_to_hub(\"kkrusere/summaryInterp_trained_led-base-16384\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "ab12d623377f45029f3d236e6a3916c1",
            "98e49d9dcaa242ccaf1c7aaf62e33af1",
            "a4c97a9419104df9be5d7ddfb83e79dd",
            "80614ad18a9548aeac19e9333167922b",
            "9b7c1c7ab97f414fa1b9b2d07014d7b4",
            "7263de39482540489a861e9d3d033f2d",
            "ec8c5c15f45d45bf93775cbb59450203",
            "80e42868477b4934b4f1e825a379cbe1",
            "184491c248454de29c17920010d358d4",
            "8dd7fbe86f8a45c98f4191dff2b03457",
            "48e044fd59ea43f9953c298152be80b0",
            "504c8134c4174368ae657c7861ef5a40",
            "246cb250357144a48900b83c3fcf890a",
            "9801036461e64f0a9bf0ad2d704e9a92",
            "2bea46f33cec433ea28a112fbe65a971",
            "0e1396b866c44dd0b9188446c27f337f",
            "0bdb41a551994d068b8fe212bacc5952",
            "7bdb4870d4bd437f85dcd9ee46cf67bf",
            "9c7053a8d5764d168ad97885f380ff3e",
            "be5fb78470aa49b99751f61e8ba2e8f6",
            "d3a6151b232d4676a0d3ddac5db0fb52",
            "a6643cf672354261af754db1be6c26d2"
          ]
        },
        "id": "fHJwxkbnyH92",
        "outputId": "e700f53c-1ad0-474b-fd8d-66757953a390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab12d623377f45029f3d236e6a3916c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/648M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "504c8134c4174368ae657c7861ef5a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/kkrusere/summaryInterp_trained_led-base-16384/commit/b256ed70422c0e9e63511dc13ccf5fa8e87fc52c', commit_message='Upload tokenizer', commit_description='', oid='b256ed70422c0e9e63511dc13ccf5fa8e87fc52c', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function for generating a summary for a single input\n",
        "# def generate_summary(text):\n",
        "#     inputs = tokenizer(text, max_length=16384, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "#     summary_ids = model.generate(inputs.input_ids, max_length=150, num_beams=2, length_penalty=2.0, early_stopping=True)\n",
        "#     return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# # Example generation\n",
        "# for text in input_texts:\n",
        "#     summary = generate_summary(text)\n",
        "#     print(\"Generated Summary:\", summary)"
      ],
      "metadata": {
        "id": "KhKaCmW8lC5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = retrieve_or_extract_video_data('https://www.youtube.com/watch?v=JXHaPjFbN_U')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywY3b49p0IG6",
        "outputId": "0dba97c4-abb2-41cf-be79-413d43c27944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 reference for video_id 'JXHaPjFbN_U' retrieved from DynamoDB.\n",
            "Data for video_id 'JXHaPjFbN_U' retrieved from S3.\n",
            "Data retrieved from AWS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = recreate_dataset_without_comments(processed_data)"
      ],
      "metadata": {
        "id": "a8zDuwf21jeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths where the model and tokenizer are saved\n",
        "model_save_path = \"./summaryInterp_trained_led-base-16384\"\n",
        "tokenizer_save_path = \"./summaryInterp_trained_led-base-16384\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_save_path)\n",
        "tokenizer = LEDTokenizer.from_pretrained(tokenizer_save_path)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "eZd4a15n0PKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQ6P6E9l03Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWJyPlyE2X5n",
        "outputId": "a5fc5b4b-b19c-4c42-98de-d5e8010b3da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['channel_name', 'video_title', 'video_description', 'sentiment_&_explanations_list'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = [\n",
        "    f\"\"\"\n",
        "    You are given information about a YouTube channel's video (Channel Name, Video Title, and Video Description are provided for context), along with viewer sentiment and explanations from various comments.\n",
        "    Summarize and provide an overall interpretation of the sentiment and explanations provided.\n",
        "\n",
        "    Channel Name: {video_data.get('channel_name', 'N/A')}\n",
        "    Video Title: {video_data.get('video_title', 'N/A')}\n",
        "    Video Description: {video_data.get('video_description', 'N/A')}\n",
        "\n",
        "    Viewer Sentiments and Explanations:\n",
        "    {video_data.get('sentiment_&_explanations_list', [])}\n",
        "\n",
        "    Instructions:\n",
        "    1. Review the input data, focusing on the sentiment and explanations.\n",
        "    2. Identify the general mood or attitude expressed by the viewers.\n",
        "    3. Provide an overall interpretation of the viewers' reactions and any specific themes or concerns they raise.\n",
        "    \"\"\"\n",
        "    for video_data in processed_data if isinstance(video_data, dict)\n",
        "]"
      ],
      "metadata": {
        "id": "0c-DHcA52ENv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, max_input_length=16384, max_output_length=16384):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)  # Move inputs to the same device as the model\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_length=max_output_length,\n",
        "        num_beams=4,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode and return the summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "JBcjKSNk2rpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and print the summary\n",
        "summary = generate_summary(input_text)\n",
        "print(\"Generated Summary:\", summary)"
      ],
      "metadata": {
        "id": "rfQTNNWz2woD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whrMuj5u23LL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOnS8d9A36WfyNq94FhYOP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab12d623377f45029f3d236e6a3916c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98e49d9dcaa242ccaf1c7aaf62e33af1",
              "IPY_MODEL_a4c97a9419104df9be5d7ddfb83e79dd",
              "IPY_MODEL_80614ad18a9548aeac19e9333167922b"
            ],
            "layout": "IPY_MODEL_9b7c1c7ab97f414fa1b9b2d07014d7b4"
          }
        },
        "98e49d9dcaa242ccaf1c7aaf62e33af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7263de39482540489a861e9d3d033f2d",
            "placeholder": "",
            "style": "IPY_MODEL_ec8c5c15f45d45bf93775cbb59450203",
            "value": "README.md:100%"
          }
        },
        "a4c97a9419104df9be5d7ddfb83e79dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e42868477b4934b4f1e825a379cbe1",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_184491c248454de29c17920010d358d4",
            "value": 5174
          }
        },
        "80614ad18a9548aeac19e9333167922b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd7fbe86f8a45c98f4191dff2b03457",
            "placeholder": "",
            "style": "IPY_MODEL_48e044fd59ea43f9953c298152be80b0",
            "value": "5.17k/5.17k[00:00&lt;00:00,445kB/s]"
          }
        },
        "9b7c1c7ab97f414fa1b9b2d07014d7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7263de39482540489a861e9d3d033f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8c5c15f45d45bf93775cbb59450203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e42868477b4934b4f1e825a379cbe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184491c248454de29c17920010d358d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dd7fbe86f8a45c98f4191dff2b03457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e044fd59ea43f9953c298152be80b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "504c8134c4174368ae657c7861ef5a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_246cb250357144a48900b83c3fcf890a",
              "IPY_MODEL_9801036461e64f0a9bf0ad2d704e9a92",
              "IPY_MODEL_2bea46f33cec433ea28a112fbe65a971"
            ],
            "layout": "IPY_MODEL_0e1396b866c44dd0b9188446c27f337f"
          }
        },
        "246cb250357144a48900b83c3fcf890a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdb41a551994d068b8fe212bacc5952",
            "placeholder": "",
            "style": "IPY_MODEL_7bdb4870d4bd437f85dcd9ee46cf67bf",
            "value": "model.safetensors:100%"
          }
        },
        "9801036461e64f0a9bf0ad2d704e9a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c7053a8d5764d168ad97885f380ff3e",
            "max": 647614116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be5fb78470aa49b99751f61e8ba2e8f6",
            "value": 647614116
          }
        },
        "2bea46f33cec433ea28a112fbe65a971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a6151b232d4676a0d3ddac5db0fb52",
            "placeholder": "",
            "style": "IPY_MODEL_a6643cf672354261af754db1be6c26d2",
            "value": "648M/648M[00:18&lt;00:00,34.1MB/s]"
          }
        },
        "0e1396b866c44dd0b9188446c27f337f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdb41a551994d068b8fe212bacc5952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdb4870d4bd437f85dcd9ee46cf67bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c7053a8d5764d168ad97885f380ff3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5fb78470aa49b99751f61e8ba2e8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3a6151b232d4676a0d3ddac5db0fb52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6643cf672354261af754db1be6c26d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}